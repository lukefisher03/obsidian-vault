**1.1:** In the above sample code, you'll see a for loop of the form "for (i=0; i < 2; i++)".  Change that "2" to a "3", recompile, and run the program.  What do you see?  Is this the expected behavior?  Why or why not?
- Since there's only two messages that get written to the pipe, attempting to read a third message would cause the program to wait. The read function is a blocking operation (by default) and if it encounters an empty pipe it will wait for a message to appear before returning.

**1.2:** In the code I gave above, the parent is the producer (it writes things into the pipe) and the child is the consumer (it pulls things out of the pipe and prints them).  What would happen if, through some mischance, the kernel process scheduler sent the child process to a CPU before it the parent process had any chance to write to the pipe?  Be specific.
- It's not a big deal if the child process gets scheduled before the parent process. The `read` function of the child is a blocking operation, it will wait until the parent sends messages to it before finishing. If `O_NONBLOCK` is set then the `read` function will just return -1.

**1.3:** In the code I gave above, what happens if the parent tries to write to the pipe when it is already full (on Linux, it has 64K of data in it already).  Be specific.  Is this a good thing?
- According to documentation, if a write is attempted on a pipe that's already full (The size of `PIPE_BUF`) then the write command does a blocking wait until it can write data into the pipe. Reading from the pipe will remove those values from it allowing for more writes. Whether or not this is a "good" thing might be subjective. Depending on your scenario it could be more or less convenient. However, this behavior is deterministic and is certainly much better than unexpected behavior. I would consider this to be a good thing as no data is getting overwritten and the write process happens in an expected and orderly way.

**1.4:** read() and write() are guaranteed by the kernel to be "atomic".  This means that while a read() or write() is happening, NOTHING will interrupt it.  Is this a good thing?  Is this atomic condition necessary?  Explain your answer.
- Yes, this is a good thing. Suppose you have multiple processes writing to the same pipe. Without atomic operations the data within each write could be interleaved according to the concurrent scheduling of processes (or threads). Atomic writes guarantee that each write will fulfill completely before anything else happens. Individual write commands may be interleaved, but the actual process of writing data is atomic so that you don't get half of one write mixed with another. This is a good thing as it helps to maintain data integrity.

**1.5:** In example 2 code above, the first line of the child code closes p\[1].  Comment out or remove that call to close(), recompile, and run the code.  What behavior do you see.  Is this expected?  Why or why not?  If I restored that the initial close() in the child code, but removed or commented out the initial close() in the parent code, what behavior would I see?  Is this consistent with _how blocking works with a pipe_?  Why or why not?
- According to documentation, if the pipe's write end isn't closed, then calling `read` will force the process to wait until it is closed. So commenting out closing the write end of the pipe in the child process before calling `read` causes the child process to be blocked. Commenting out the initial closing of the reading end of the pipe in the parent process doesn't actually effect the output of the program. However, the pipe never officially closes as not all of it's file descriptors have been closed. This is consistent with how the blocking behavior of reading and writing to pipes works.